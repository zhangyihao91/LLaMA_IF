{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "1a059953-e2d2-49be-a08a-9226ea2f48bd",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import json\n",
    "import math\n",
    "import hiq\n",
    "\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "\n",
    "from llama.model import precompute_freqs_cis\n",
    "from llama.model import apply_rotary_emb\n",
    "from llama.model import ModelArgs, Attention, RMSNorm, FeedForward\n",
    "from llama import Tokenizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "51dbadf3-8e2a-4161-ba10-25b6f6761fbd",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'dim': 8192,\n",
       " 'multiple_of': 256,\n",
       " 'n_heads': 64,\n",
       " 'n_layers': 80,\n",
       " 'norm_eps': 1e-05,\n",
       " 'vocab_size': -1}"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "with open('./65B/params.json', \"r\") as f:\n",
    "    params = json.loads(f.read())\n",
    "\n",
    "params"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "9bc706d8-901f-47e1-9f13-6eb052b36eb9",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_args: ModelArgs = ModelArgs(\n",
    "    max_seq_len=512, max_batch_size=1, **params\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "583b0608-a3e0-4b5f-a775-93d8ff769904",
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenizer = Tokenizer('../tokenizer.model')\n",
    "model_args.vocab_size = tokenizer.n_words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "80815a6e-323a-4041-afdc-d924052a0ebe",
   "metadata": {
    "jupyter": {
     "source_hidden": true
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "class Attention(nn.Module):\n",
    "    def __init__(self, args: ModelArgs):\n",
    "        super().__init__()\n",
    "\n",
    "        self.n_local_heads = args.n_heads // 1\n",
    "        self.head_dim = args.dim // args.n_heads\n",
    "\n",
    "        self.wq = nn.Linear(\n",
    "            args.dim,\n",
    "            args.n_heads * self.head_dim,\n",
    "            bias=False,\n",
    "        )\n",
    "        self.wk = nn.Linear(\n",
    "            args.dim,\n",
    "            args.n_heads * self.head_dim,\n",
    "            bias=False,\n",
    "        )\n",
    "        self.wv = nn.Linear(\n",
    "            args.dim,\n",
    "            args.n_heads * self.head_dim,\n",
    "            bias=False,\n",
    "        )\n",
    "        self.wo = nn.Linear(\n",
    "            args.n_heads * self.head_dim,\n",
    "            args.dim,\n",
    "            bias=False,\n",
    "        )\n",
    "        self.cache_k = torch.zeros(\n",
    "            (args.max_batch_size, args.max_seq_len, self.n_local_heads, self.head_dim)\n",
    "        )\n",
    "        self.cache_v = torch.zeros(\n",
    "            (args.max_batch_size, args.max_seq_len, self.n_local_heads, self.head_dim)\n",
    "        )\n",
    "        if hiq.get_env_bool(\"KV_CAHCHE_IN_GPU\", True):\n",
    "            self.cache_k = self.cache_k.cuda()\n",
    "            self.cache_v = self.cache_v.cuda()\n",
    "\n",
    "    def forward(self, x: torch.Tensor, freqs_cis: torch.Tensor):\n",
    "        bsz, seqlen = 1, 1\n",
    "        start_pos = 262\n",
    "        xq, xk, xv = self.wq(x), self.wk(x), self.wv(x)\n",
    "\n",
    "        xq = xq.view(bsz, seqlen, self.n_local_heads, self.head_dim)\n",
    "        xk = xk.view(bsz, seqlen, self.n_local_heads, self.head_dim)\n",
    "        xv = xv.view(bsz, seqlen, self.n_local_heads, self.head_dim)\n",
    "\n",
    "        xq, xk = apply_rotary_emb(xq, xk, freqs_cis=freqs_cis)\n",
    "\n",
    "        self.cache_k = self.cache_k.to(xq)\n",
    "        self.cache_v = self.cache_v.to(xq)\n",
    "\n",
    "        self.cache_k[:bsz, start_pos : start_pos + seqlen] = xk\n",
    "        self.cache_v[:bsz, start_pos : start_pos + seqlen] = xv\n",
    "\n",
    "        keys = self.cache_k[:bsz, : start_pos + seqlen]\n",
    "        values = self.cache_v[:bsz, : start_pos + seqlen]\n",
    "\n",
    "        xq = xq.transpose(1, 2)\n",
    "        keys = keys.transpose(1, 2)\n",
    "        values = values.transpose(1, 2)\n",
    "        scores = torch.matmul(xq, keys.transpose(2, 3)) / math.sqrt(self.head_dim)\n",
    "        scores = F.softmax(scores.float(), dim=-1).type_as(xq)\n",
    "        output = torch.matmul(scores, values)  # (bs, n_local_heads, slen, head_dim)\n",
    "        output = output.transpose(\n",
    "            1, 2\n",
    "        ).contiguous().view(bsz, seqlen, -1)\n",
    "\n",
    "        return self.wo(output)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "b86eca39-2e1d-4de0-a801-b18aaa5da210",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "attention = Attention(model_args)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "ee4c0d47-eda4-4956-b25e-82402b13c5c8",
   "metadata": {},
   "outputs": [],
   "source": [
    "class TransformerBlock(nn.Module):\n",
    "    def __init__(self, layer_id: int, args: ModelArgs):\n",
    "        super().__init__()\n",
    "        self.n_heads = args.n_heads\n",
    "        self.dim = args.dim\n",
    "        self.head_dim = args.dim // args.n_heads\n",
    "        self.attention = attention\n",
    "        self.feed_forward = FeedForward(\n",
    "            dim=args.dim, hidden_dim=4 * args.dim, multiple_of=args.multiple_of\n",
    "        )\n",
    "        self.layer_id = layer_id\n",
    "        self.attention_norm = RMSNorm(args.dim, eps=args.norm_eps)\n",
    "        self.ffn_norm = RMSNorm(args.dim, eps=args.norm_eps)\n",
    "\n",
    "    def forward(self, x: torch.Tensor, freqs_cis: torch.Tensor):\n",
    "        h = x + self.attention.forward(self.attention_norm(x), freqs_cis)\n",
    "        out = h + self.feed_forward.forward(self.ffn_norm(h))\n",
    "        return out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "b8b8575c-fc25-4a82-995a-eab7f56b4d96",
   "metadata": {},
   "outputs": [],
   "source": [
    "tfb = TransformerBlock(0, model_args)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "13a641e5-1bcc-4072-ac11-6551ab60736e",
   "metadata": {},
   "outputs": [],
   "source": [
    "params = model_args"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "b744fbad-8bc0-415c-82e5-bb5ed83558f3",
   "metadata": {},
   "outputs": [],
   "source": [
    "h = torch.randn((1,1,8192), dtype = torch.float16).cuda()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "1d63e093-b254-4b23-8876-80eb02293749",
   "metadata": {},
   "outputs": [],
   "source": [
    "freqs_cis = precompute_freqs_cis(params.dim // params.n_heads, params.max_seq_len * 2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "9ab40ba3-3142-4117-bc18-823ec91c6449",
   "metadata": {},
   "outputs": [],
   "source": [
    "freqs_cis = freqs_cis[262:263]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fe1fcdfc-a069-466f-9840-d2cd9d2d9a56",
   "metadata": {},
   "source": [
    "### Export part"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "73e67d85-de25-48b2-8a66-d04b51a1ed9a",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/root/Workspace/LLaMA_IF/llama/model.py:87: TracerWarning: Converting a tensor to a Python integer might cause the trace to be incorrect. We can't record the data flow of Python values, so this value will be treated as a constant in the future. This means that the trace might not generalize to other inputs!\n",
      "  xq_shape[-1] = int(xq_shape[-1]/2)\n",
      "/root/Workspace/LLaMA_IF/llama/model.py:90: TracerWarning: Converting a tensor to a Python integer might cause the trace to be incorrect. We can't record the data flow of Python values, so this value will be treated as a constant in the future. This means that the trace might not generalize to other inputs!\n",
      "  xk_shape[-1] = int(xk_shape[-1]/2)\n",
      "/root/Workspace/LLaMA_IF/llama/model.py:58: TracerWarning: Converting a tensor to a Python boolean might cause the trace to be incorrect. We can't record the data flow of Python values, so this value will be treated as a constant in the future. This means that the trace might not generalize to other inputs!\n",
      "  assert freqs_cis.shape == (x.shape[1], x.shape[-2], 2)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "================ Diagnostic Run torch.onnx.export version 2.0.0 ================\n",
      "verbose: False, log level: Level.ERROR\n",
      "======================= 0 NONE 0 NOTE 0 WARNING 0 ERROR ========================\n",
      "\n"
     ]
    }
   ],
   "source": [
    "with torch.no_grad():\n",
    "    torch.onnx.export(tfb.half().cuda(), (h,freqs_cis.to(h.device)), 'transformerblock_65B_sq1_last_iter_noweight_v1.onnx', opset_version=14)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "36fa19be-c805-438b-a56b-3818ac37d1c5",
   "metadata": {},
   "source": [
    "### Export Embedding "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "3b99ca06-6d5f-4bd2-a315-9cc3767274d6",
   "metadata": {},
   "outputs": [],
   "source": [
    "token_embedding = nn.Embedding(model_args.vocab_size, model_args.dim)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "2dcf3b9f-306a-418e-98cf-216921fdfbc0",
   "metadata": {},
   "outputs": [],
   "source": [
    "tokens = torch.randint(0,10, (1,1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "d067a938-53e0-456d-8da3-1beca5981dce",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "================ Diagnostic Run torch.onnx.export version 2.0.0 ================\n",
      "verbose: False, log level: Level.ERROR\n",
      "======================= 0 NONE 0 NOTE 0 WARNING 0 ERROR ========================\n",
      "\n"
     ]
    }
   ],
   "source": [
    "with torch.no_grad():\n",
    "    torch.onnx.export(token_embedding.half().cuda(), tokens.cuda(), '65B_token_embedding.onnx', opset_version=14)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8628a199-e59e-4218-9380-dc4e5723cbc9",
   "metadata": {},
   "source": [
    "### Export Last FC "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "9f4875e9-9a77-4de9-8143-9e2e61cc10c2",
   "metadata": {},
   "outputs": [],
   "source": [
    "last_fc_layer = nn.Linear(model_args.dim, model_args.vocab_size, bias = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "5e21c008-484f-4313-b360-fcc25af98170",
   "metadata": {},
   "outputs": [],
   "source": [
    "dummy_input = torch.randn((1,1,8192), dtype = torch.float16)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "847ac550-f067-477c-b5ed-99fe6436b968",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "================ Diagnostic Run torch.onnx.export version 2.0.0 ================\n",
      "verbose: False, log level: Level.ERROR\n",
      "======================= 0 NONE 0 NOTE 0 WARNING 0 ERROR ========================\n",
      "\n"
     ]
    }
   ],
   "source": [
    "with torch.no_grad():\n",
    "    torch.onnx.export(last_fc_layer.half().cuda(), dummy_input.cuda(), '65B_last_fc_layer.onnx', opset_version=14)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "291ea36b-7df3-4d01-b266-927e36f6029f",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
