{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "e9002295-b5dc-45ca-8b26-9a3084c93778",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import json\n",
    "import math\n",
    "import hiq\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "\n",
    "from llama import ModelArgs, Transformer, Tokenizer, LLaMA\n",
    "from llama.generation import sample_top_p"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "31bb552a-21bf-44ee-b817-440dc7387402",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('../7B/params.json', \"r\") as f:\n",
    "    params = json.loads(f.read())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "5649ba6b-0b0b-4deb-b5c7-1346a47d1509",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_args: ModelArgs = ModelArgs(\n",
    "    max_seq_len=512, max_batch_size=128, **params\n",
    ")\n",
    "tokenizer = Tokenizer('../tokenizer.model')\n",
    "model_args.vocab_size = tokenizer.n_words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "161d2f5e-b4ac-46e1-917a-486544f084fd",
   "metadata": {},
   "outputs": [],
   "source": [
    "temperature: float = 0.8\n",
    "top_p: float = 0.95\n",
    "max_seq_len=512"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ca5bc278-3338-47fc-9884-b471f0adb28c",
   "metadata": {},
   "source": [
    "### Initialize new modules"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "f3a682d9-db2a-4c98-aae1-8753c8764572",
   "metadata": {},
   "outputs": [],
   "source": [
    "from llama.model import FeedForward, apply_rotary_emb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "268b0336-0488-427e-8dd5-cb4a9291aa3d",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "class RMSNorm(torch.nn.Module):\n",
    "    def __init__(self, dim: int, eps: float = 1e-6):\n",
    "        super().__init__()\n",
    "        self.eps = eps\n",
    "        self.weight = nn.Parameter(torch.ones(dim))\n",
    "\n",
    "    def _norm(self, x):\n",
    "        return x * torch.rsqrt(x.pow(2).mean(-1, keepdim=True) + self.eps)\n",
    "\n",
    "    def forward(self, x):\n",
    "        output = self._norm(x.float()).type_as(x)\n",
    "\n",
    "        return output * self.weight"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "37ddd663-c101-44f5-8890-3811688c9ae2",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "class Attention(nn.Module):\n",
    "    def __init__(self, args: ModelArgs):\n",
    "        super().__init__()\n",
    "\n",
    "        self.n_local_heads = args.n_heads // 1\n",
    "        self.max_batch_size = args.max_batch_size\n",
    "        self.head_dim = args.dim // args.n_heads\n",
    "    \n",
    "        self.wq = nn.Linear(\n",
    "            args.dim,\n",
    "            args.n_heads * self.head_dim,\n",
    "            bias=False,\n",
    "        )\n",
    "        self.wk = nn.Linear(\n",
    "            args.dim,\n",
    "            args.n_heads * self.head_dim,\n",
    "            bias=False,\n",
    "        )\n",
    "        self.wv = nn.Linear(\n",
    "            args.dim,\n",
    "            args.n_heads * self.head_dim,\n",
    "            bias=False,\n",
    "        )\n",
    "        self.wo = nn.Linear(\n",
    "            args.n_heads * self.head_dim,\n",
    "            args.dim,\n",
    "            bias=False,\n",
    "        )\n",
    "        self.cache_k = torch.zeros(\n",
    "            (self.max_batch_size, args.max_seq_len, self.n_local_heads, self.head_dim)\n",
    "        )\n",
    "        self.cache_v = torch.zeros(\n",
    "            (self.max_batch_size, args.max_seq_len, self.n_local_heads, self.head_dim)\n",
    "        )\n",
    "        if hiq.get_env_bool(\"KV_CAHCHE_IN_GPU\", True):\n",
    "            self.cache_k = self.cache_k.cuda()\n",
    "            self.cache_v = self.cache_v.cuda()\n",
    "\n",
    "    def forward(self, x: torch.Tensor, freqs_cis:torch.Tensor):\n",
    "        start_pos = 262  \n",
    "        bsz, seqlen = self.max_batch_size, 1 \n",
    "        xq, xk, xv = self.wq(x), self.wk(x), self.wv(x)\n",
    "\n",
    "        xq = xq.view(bsz, seqlen, self.n_local_heads, self.head_dim)\n",
    "        xk = xk.view(bsz, seqlen, self.n_local_heads, self.head_dim)\n",
    "        xv = xv.view(bsz, seqlen, self.n_local_heads, self.head_dim)\n",
    "        xq, xk = apply_rotary_emb(xq, xk, freqs_cis=freqs_cis)\n",
    "\n",
    "        self.cache_k = self.cache_k.to(xq)\n",
    "        self.cache_v = self.cache_v.to(xq)\n",
    "\n",
    "        self.cache_k[:bsz, start_pos : start_pos + seqlen] = xk\n",
    "        self.cache_v[:bsz, start_pos : start_pos + seqlen] = xv\n",
    "\n",
    "        keys = self.cache_k[:bsz, : start_pos + seqlen]\n",
    "        values = self.cache_v[:bsz, : start_pos + seqlen]\n",
    "\n",
    "        xq = xq.transpose(1, 2)\n",
    "        keys = keys.transpose(1, 2)\n",
    "        values = values.transpose(1, 2)\n",
    "        scores = torch.matmul(xq, keys.transpose(2, 3)) / math.sqrt(self.head_dim)\n",
    "        #if mask is not None:\n",
    "            #scores = scores + mask  # (bs, n_local_heads, slen, cache_len + slen)\n",
    "        scores = F.softmax(scores.float(), dim=-1).type_as(xq)\n",
    "        output = torch.matmul(scores, values)  # (bs, n_local_heads, slen, head_dim)\n",
    "        output = output.transpose(\n",
    "            1, 2\n",
    "        ).contiguous().view(bsz, seqlen, -1)\n",
    "\n",
    "        return self.wo(output)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "809055bc-adb4-40fa-85da-bb69706e0848",
   "metadata": {},
   "outputs": [],
   "source": [
    "attention = Attention(model_args)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "90905950-4fa8-43b7-9605-f2c227179839",
   "metadata": {},
   "outputs": [],
   "source": [
    "ffn = FeedForward(dim=model_args.dim, hidden_dim=4 * model_args.dim, multiple_of=model_args.multiple_of).half()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "7da3b23b-0b1e-409f-8228-36085c939374",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "attention_norm = RMSNorm(model_args.dim, eps=model_args.norm_eps).half()\n",
    "ffn_norm = RMSNorm(model_args.dim, eps=model_args.norm_eps).half()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "a1eb62b3-8a29-40d4-8470-1a5682c8f1da",
   "metadata": {},
   "outputs": [],
   "source": [
    "class TransformerBlock(nn.Module):\n",
    "    def __init__(self, layer_id: int, args: ModelArgs):\n",
    "        super().__init__()\n",
    "        self.n_heads = args.n_heads\n",
    "        self.dim = args.dim\n",
    "        self.head_dim = args.dim // args.n_heads\n",
    "        self.attention = attention\n",
    "        self.feed_forward = ffn\n",
    "        self.layer_id = layer_id\n",
    "        self.attention_norm = attention_norm\n",
    "        self.ffn_norm = ffn_norm\n",
    "\n",
    "    def forward(self, x: torch.Tensor, freqs_cis:torch.Tensor):\n",
    "        #print(freqs_cis.shape)\n",
    "        h = x + self.attention.forward(self.attention_norm(x), freqs_cis)\n",
    "        out = h + self.feed_forward.forward(self.ffn_norm(h))\n",
    "        return out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "4389d6ad-3eef-4e9d-93f5-ba6088e87ffc",
   "metadata": {},
   "outputs": [],
   "source": [
    "tf_block = TransformerBlock(0, model_args)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "7a009faa-08dc-4663-b6f4-a6576db7fdea",
   "metadata": {},
   "outputs": [],
   "source": [
    "save_file = 'tf_block_static_bsz128_sq1_last_iter_v1.onnx'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "119bf392-44ff-4685-a32e-e125cec50ff1",
   "metadata": {},
   "outputs": [],
   "source": [
    "h = torch.randn((model_args.max_batch_size, 1 ,model_args.dim), dtype = torch.float16)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "e70bc428-057b-4327-9e2b-d0a1f26c2bc3",
   "metadata": {},
   "outputs": [],
   "source": [
    "freq_cis = torch.randn((1,64,2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "9ffdab31-9d37-4341-869a-037e5283c2b4",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/root/Workspace/LLaMA_IF/llama/model.py:87: TracerWarning: Converting a tensor to a Python integer might cause the trace to be incorrect. We can't record the data flow of Python values, so this value will be treated as a constant in the future. This means that the trace might not generalize to other inputs!\n",
      "  xq_shape[-1] = int(xq_shape[-1]/2)\n",
      "/root/Workspace/LLaMA_IF/llama/model.py:90: TracerWarning: Converting a tensor to a Python integer might cause the trace to be incorrect. We can't record the data flow of Python values, so this value will be treated as a constant in the future. This means that the trace might not generalize to other inputs!\n",
      "  xk_shape[-1] = int(xk_shape[-1]/2)\n",
      "/root/Workspace/LLaMA_IF/llama/model.py:58: TracerWarning: Converting a tensor to a Python boolean might cause the trace to be incorrect. We can't record the data flow of Python values, so this value will be treated as a constant in the future. This means that the trace might not generalize to other inputs!\n",
      "  assert freqs_cis.shape == (x.shape[1], x.shape[-2], 2)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "================ Diagnostic Run torch.onnx.export version 2.0.0 ================\n",
      "verbose: False, log level: Level.ERROR\n",
      "======================= 0 NONE 0 NOTE 0 WARNING 0 ERROR ========================\n",
      "\n"
     ]
    }
   ],
   "source": [
    "with torch.no_grad():\n",
    "    torch.onnx.export(tf_block.half().cuda(), (h.cuda(), freq_cis.cuda()), save_file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1322c709-f6d3-488e-bccb-d3370e7b36cd",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "81319c11-d659-49d6-a4c5-1a15342d53c7",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1e268ee9-aa7f-4912-9efc-9cde0f1d7d42",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1f095430-fb37-4bb9-a0ef-a8711af83420",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
